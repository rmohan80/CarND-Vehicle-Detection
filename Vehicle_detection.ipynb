{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ram\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "# NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# for scikit-learn >= 0.18 use:\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll define functions to extract HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=False):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "    \n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, cspace='RGB', orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0, spatial_size=(32, 32), hist_bins=32):\n",
    "    # Create a list to append feature vectors to\n",
    "\n",
    "    features = []\n",
    "    \n",
    "    print (\"total images to train = \", len(imgs))\n",
    "\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        \n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)     \n",
    "            \n",
    "        # Add spatial features & hist features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        file_features.append(spatial_features)\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        \n",
    "        file_features.append(hist_features)\n",
    "\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        # Append all the different features to the features list\n",
    "        file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we'll read in both the car images and non-car images to train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in car and non-car images\n",
    "cars = glob.glob('vehicles/**/*.png', recursive=True)\n",
    "notcars = glob.glob('non-vehicles/**/*.png', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the SVC - commented after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### TODO: Tweak these parameters and see how the results change.\\ncolorspace = \\'YCrCb\\' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\\norient = 9\\npix_per_cell = 8\\ncell_per_block = 2\\nhog_channel = \\'ALL\\' # Can be 0, 1, 2, or \"ALL\"\\nspatial_size = (32,32)\\nhist_bins = 32\\n\\nt=time.time()\\ncar_features = extract_features(cars, cspace=colorspace, orient=orient, \\n                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \\n                        hog_channel=hog_channel, spatial_size=spatial_size, hist_bins=hist_bins)\\nnotcar_features = extract_features(notcars, cspace=colorspace, orient=orient, \\n                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \\n                        hog_channel=hog_channel, spatial_size=spatial_size, hist_bins=hist_bins)\\n\\nt2 = time.time()\\nprint(round(t2-t, 2), \\'Seconds to extract HOG features...\\')\\n# Create an array stack of feature vectors\\nX = np.vstack((car_features, notcar_features)).astype(np.float64)                        \\n# Fit a per-column scaler\\nX_scaler = StandardScaler().fit(X)\\n# Apply the scaler to X\\nscaled_X = X_scaler.transform(X)\\n\\n# Define the labels vector\\ny = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\\n\\n\\n# Split up data into randomized training and test sets\\nrand_state = np.random.randint(0, 100)\\nX_train, X_test, y_train, y_test = train_test_split(\\n    scaled_X, y, test_size=0.2, random_state=rand_state)\\n\\nprint(\\'Using:\\',orient,\\'orientations\\',pix_per_cell,\\n    \\'pixels per cell\\', cell_per_block,\\'cells per block\\', spatial_size, \\'spatial_size and\\',\\n     hist_bins, \\'hist_bins\\')\\nprint(\\'Feature vector length:\\', len(X_train[0]))\\n# Use a linear SVC \\nsvc = LinearSVC()\\n# Check the training time for the SVC\\nt=time.time()\\nsvc.fit(X_train, y_train)\\nt2 = time.time()\\nprint(round(t2-t, 2), \\'Seconds to train SVC...\\')\\n\\n# Save our training data weights\\nimport pickle\\n\\npickle.dump( svc, open( \"svc.p\", \"wb\" ) )\\npickle.dump(X_scaler, open(\"X_scaler.p\", \"wb\"))\\nprint (\"Saved pickle\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "colorspace = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32,32)\n",
    "hist_bins = 32\n",
    "\n",
    "t=time.time()\n",
    "car_features = extract_features(cars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_size=spatial_size, hist_bins=hist_bins)\n",
    "notcar_features = extract_features(notcars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_size=spatial_size, hist_bins=hist_bins)\n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell', cell_per_block,'cells per block', spatial_size, 'spatial_size and',\n",
    "     hist_bins, 'hist_bins')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "\n",
    "# Save our training data weights\n",
    "import pickle\n",
    "\n",
    "pickle.dump( svc, open( \"svc.p\", \"wb\" ) )\n",
    "pickle.dump(X_scaler, open(\"X_scaler.p\", \"wb\"))\n",
    "print (\"Saved pickle\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the accuracy of the SVC - commented after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\\n# Check the prediction time for a single sample\\nt=time.time()\\nn_predict = 10\\nprint('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\\nprint('For these',n_predict, 'labels: ', y_test[0:n_predict])\\nt2 = time.time()\\nprint(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hog sub sampling window search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# import our saved svm object\\n#Commented out - uncomment for debug purposes\\nsvc =  pickle.load( open( \"svc.p\", \"rb\" ) )\\nX_scaler = pickle.load(open( \"X_scaler.p\", \"rb\" ))\\nspatial_size =(32,32)\\nhist_bins = 32\\norient = 9\\npix_per_cell = 8\\ncell_per_block = 2\\nystart = 400\\nystop = 656\\nscale = 1.8\\n\\nimg = mpimg.imread(\\'test_frame.jpg\\')\\n    \\nout_img, heatmap = find_cars(img, ystart, ystop, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\\n\\nplt.figure(figsize=(10,10))\\nplt.imshow(out_img)\\nplt.show()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "\n",
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "\n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    scale_choose = [1.3, 1.5, 1.8]\n",
    "    draw_img = np.copy(img)\n",
    "    heatmap = np.zeros_like(img[:,:,0])\n",
    "    img = img.astype(np.float32)/255\n",
    "    for scale in scale_choose:\n",
    "        img_tosearch = img[ystart:ystop,:,:]\n",
    "        ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "\n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "        # Compute individual channel HOG features for the entire image\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "\n",
    "        # Define blocks and steps as above\n",
    "        nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "        nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "        nfeat_per_block = orient*cell_per_block**2\n",
    "        # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "        window = 64\n",
    "        nblocks_per_window = (window // pix_per_cell)-1 \n",
    "        if scale == 1.8:\n",
    "            cells_per_step = 3\n",
    "        else:\n",
    "            cells_per_step = 2\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb*cells_per_step\n",
    "                xpos = xb*cells_per_step\n",
    "                # Extract HOG for this patch\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                xleft = xpos*pix_per_cell\n",
    "                ytop = ypos*pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "                # Get color features\n",
    "                spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "                # Scale features and make a prediction\n",
    "                test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "                #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "                test_prediction = svc.predict(test_features)\n",
    "\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                    heatmap[ytop_draw+ystart:ytop_draw+win_draw+ystart, xbox_left:xbox_left+win_draw] += 1\n",
    "\n",
    "    return draw_img, heatmap\n",
    "\n",
    "'''# import our saved svm object\n",
    "#Commented out - uncomment for debug purposes\n",
    "svc =  pickle.load( open( \"svc.p\", \"rb\" ) )\n",
    "X_scaler = pickle.load(open( \"X_scaler.p\", \"rb\" ))\n",
    "spatial_size =(32,32)\n",
    "hist_bins = 32\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1.8\n",
    "\n",
    "img = mpimg.imread('test_frame.jpg')\n",
    "    \n",
    "out_img, heatmap = find_cars(img, ystart, ystop, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(out_img)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Heat Map to consolidate multiple detections and remove false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Debug - not used for production run\\n# import our saved svm object\\nsvc =  pickle.load( open( \"svc.p\", \"rb\" ) )\\nX_scaler = pickle.load(open( \"X_scaler.p\", \"rb\" ))\\nspatial_size =(32,32)\\nhist_bins = 32\\norient = 9\\npix_per_cell = 8\\ncell_per_block = 2\\nystart = 400\\nystop = 656\\n\\n# Read in image similar to one shown above \\nimg = mpimg.imread(\\'test_frame.jpg\\')\\nout_img, heatmap = find_cars(img, ystart, ystop, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\\n\\n# Apply threshold to help remove false positives\\nheat = apply_threshold(heatmap,1)\\n\\n# Visualize the heatmap when displaying    \\nheatmap = np.clip(heat, 0, 255)\\n\\n# Find final boxes from heatmap using label function\\nlabels = label(heatmap)\\ndraw_img, bbox = draw_labeled_bboxes(np.copy(img), labels)\\n\\nfig = plt.figure()\\nplt.subplot(121)\\nplt.imshow(draw_img)\\nplt.title(\\'Car Positions\\')\\nplt.subplot(122)\\nplt.imshow(heatmap, cmap=\\'hot\\')\\nplt.title(\\'Heat Map\\')\\nfig.tight_layout()\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    all_box = []\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        all_box.append(bbox)\n",
    "    # Return the image and the bound boxes\n",
    "    return img, all_box\n",
    "\n",
    "'''#Debug - not used for production run\n",
    "# import our saved svm object\n",
    "svc =  pickle.load( open( \"svc.p\", \"rb\" ) )\n",
    "X_scaler = pickle.load(open( \"X_scaler.p\", \"rb\" ))\n",
    "spatial_size =(32,32)\n",
    "hist_bins = 32\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "\n",
    "# Read in image similar to one shown above \n",
    "img = mpimg.imread('test_frame.jpg')\n",
    "out_img, heatmap = find_cars(img, ystart, ystop, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "# Apply threshold to help remove false positives\n",
    "heat = apply_threshold(heatmap,1)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# Find final boxes from heatmap using label function\n",
    "labels = label(heatmap)\n",
    "draw_img, bbox = draw_labeled_bboxes(np.copy(img), labels)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pipeline defintion - put together all that we learnt so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Debug test on few images the pipeline\\n# Read in image similar to one shown above \\nimg = mpimg.imread('test_images/test1.jpg')\\n\\nfinal_output = process_image(img)\\n\\nplt.imshow(final_output)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Car():\n",
    "    def __init__(self):\n",
    "        #Previous frames heatmaps\n",
    "        self.heatmap = np.array([None]*10)\n",
    "        #first frame \n",
    "        self.first_frame = True\n",
    "        self.smoothened = 10\n",
    "global vehicle_detected\n",
    "vehicle_detected = Car()\n",
    "\n",
    "# One time run required to initialize SVM\n",
    "# import our saved svm object\n",
    "svc =  pickle.load( open( \"svc.p\", \"rb\" ) )\n",
    "X_scaler = pickle.load(open( \"X_scaler.p\", \"rb\" ))\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    \n",
    "    orient = 9\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    spatial_size = (32,32)\n",
    "    hist_bins = 32\n",
    "    ystart = 400\n",
    "    ystop = 656\n",
    "\n",
    "    out_img, heatmap = find_cars(image, ystart, ystop, svc, X_scaler, \n",
    "                                 orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    \n",
    "    if vehicle_detected.first_frame == True:\n",
    "        applied_threshold = apply_threshold(np.copy(heatmap), 1)\n",
    "        #make the history same as the first frame\n",
    "        vehicle_detected.heatmap = np.array([applied_threshold] * vehicle_detected.smoothened)\n",
    "        vehicle_detected.first_frame = False\n",
    "        labels = label(applied_threshold)\n",
    "    else:    \n",
    "        #look into previous frames   \n",
    "        vehicle_detected.heatmap[0:-1] = vehicle_detected.heatmap[1:]\n",
    "        vehicle_detected.heatmap[-1] = heatmap\n",
    "        new_previous_frame_threshold = vehicle_detected.heatmap.sum(axis=0)\n",
    "\n",
    "        applied_threshold = apply_threshold(np.copy(new_previous_frame_threshold), vehicle_detected.smoothened*2+5)\n",
    "        labels = label(applied_threshold)\n",
    "        \n",
    "    draw_labeled, bbox = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    #bias the position of the detected region by adding +1 to it\n",
    "    vehicle_detected.heatmap[-1] = add_heat(vehicle_detected.heatmap[-1], bbox)\n",
    "\n",
    "    return draw_labeled\n",
    "\n",
    "'''# Debug test on few images the pipeline\n",
    "# Read in image similar to one shown above \n",
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "final_output = process_image(img)\n",
    "\n",
    "plt.imshow(final_output)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with starttime: 0 and endtime: 5\n",
      "Output file: project_video_output_0.mp4\n",
      "[MoviePy] >>>> Building video project_video_output_0.mp4\n",
      "[MoviePy] Writing video project_video_output_0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [08:35<00:04,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_0.mp4 \n",
      "\n",
      "Wall time: 8min 40s\n",
      "Processing with starttime: 5 and endtime: 10\n",
      "[MoviePy] >>>> Building video project_video_output_5.mp4\n",
      "[MoviePy] Writing video project_video_output_5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [08:15<00:03,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_5.mp4 \n",
      "\n",
      "Wall time: 8min 19s\n",
      "Processing with starttime: 10 and endtime: 15\n",
      "[MoviePy] >>>> Building video project_video_output_10.mp4\n",
      "[MoviePy] Writing video project_video_output_10.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [08:23<00:04,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_10.mp4 \n",
      "\n",
      "Wall time: 8min 28s\n",
      "Processing with starttime: 15 and endtime: 20\n",
      "[MoviePy] >>>> Building video project_video_output_15.mp4\n",
      "[MoviePy] Writing video project_video_output_15.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [07:53<00:03,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_15.mp4 \n",
      "\n",
      "Wall time: 7min 56s\n",
      "Processing with starttime: 20 and endtime: 25\n",
      "[MoviePy] >>>> Building video project_video_output_20.mp4\n",
      "[MoviePy] Writing video project_video_output_20.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [07:25<00:03,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_20.mp4 \n",
      "\n",
      "Wall time: 7min 29s\n",
      "Processing with starttime: 25 and endtime: 30\n",
      "[MoviePy] >>>> Building video project_video_output_25.mp4\n",
      "[MoviePy] Writing video project_video_output_25.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [07:14<00:03,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_25.mp4 \n",
      "\n",
      "Wall time: 7min 17s\n",
      "Processing with starttime: 30 and endtime: 35\n",
      "[MoviePy] >>>> Building video project_video_output_30.mp4\n",
      "[MoviePy] Writing video project_video_output_30.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [07:34<00:03,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_30.mp4 \n",
      "\n",
      "Wall time: 7min 37s\n",
      "Processing with starttime: 35 and endtime: 40\n",
      "[MoviePy] >>>> Building video project_video_output_35.mp4\n",
      "[MoviePy] Writing video project_video_output_35.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [07:45<00:03,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_35.mp4 \n",
      "\n",
      "Wall time: 7min 49s\n",
      "Processing with starttime: 40 and endtime: 45\n",
      "[MoviePy] >>>> Building video project_video_output_40.mp4\n",
      "[MoviePy] Writing video project_video_output_40.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████▋| 125/126 [07:22<00:03,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_40.mp4 \n",
      "\n",
      "Wall time: 7min 25s\n",
      "Processing with starttime: 45 and endtime: 50.4\n",
      "[MoviePy] >>>> Building video project_video_output_45.mp4\n",
      "[MoviePy] Writing video project_video_output_45.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 135/135 [07:56<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_45.mp4 \n",
      "\n",
      "Wall time: 8min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'white_output = \\'project_video_output.mp4\\'\\nclip1 = VideoFileClip(\"project_video.mp4\").subclip(0,10)\\nwhite_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\\n%time white_clip.write_videofile(white_output, audio=False)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "imageio.plugins.ffmpeg.download()\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "# WOrkaround to avoid memory hog issues + easy to check at every 5 second interval output\n",
    "for i in range(0,50,5):\n",
    "    \n",
    "    white_output = 'project_video_output_' + str(i) + '.mp4'\n",
    "    if i == 0:\n",
    "        print(\"Processing with starttime: \" + str(i) + \" and endtime: \" + str(i+5))\n",
    "        print(\"Output file: \" + white_output)\n",
    "        clip1 = VideoFileClip(\"project_video.mp4\").subclip(i, i+5)\n",
    "    elif i == 45:\n",
    "        print(\"Processing with starttime: \" + str(i) + \" and endtime: \" + str(50.4))\n",
    "        clip1 = VideoFileClip(\"project_video.mp4\").subclip(i, 50.4)\n",
    "    else:\n",
    "        \n",
    "        print(\"Processing with starttime: \" + str(i) + \" and endtime: \" + str(i+5))\n",
    "        clip1 = VideoFileClip(\"project_video.mp4\").subclip(i, i+5)\n",
    "        \n",
    "    white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "    %time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "\n",
    "'''white_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,10)\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Join clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [01:53<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "clip1 = VideoFileClip(\"project_video_output_0.mp4\")\n",
    "clip2 = VideoFileClip(\"project_video_output_5.mp4\")\n",
    "clip3 = VideoFileClip(\"project_video_output_10.mp4\")\n",
    "clip4 = VideoFileClip(\"project_video_output_15.mp4\")\n",
    "clip5 = VideoFileClip(\"project_video_output_20.mp4\")\n",
    "clip6 = VideoFileClip(\"project_video_output_25.mp4\")\n",
    "clip7 = VideoFileClip(\"project_video_output_30.mp4\")\n",
    "clip8 = VideoFileClip(\"project_video_output_35.mp4\")\n",
    "clip9 = VideoFileClip(\"project_video_output_40.mp4\")\n",
    "clip10 = VideoFileClip(\"project_video_output_45.mp4\")\n",
    "\n",
    "final_clip = concatenate_videoclips([clip1,clip2,clip3,clip4,clip5,clip6,clip7,clip8,clip9,clip10])\n",
    "\n",
    "final_clip.write_videofile(\"project_video_output.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
